{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seed=122334445\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mcg   Gvh   Alm   Mit  Erl  Pox   Vac   Nuc     class\n",
      "0  0.51  0.40  0.56  0.17  0.5  0.5  0.49  0.22  negative\n",
      "1  0.40  0.39  0.60  0.15  0.5  0.0  0.58  0.30  negative\n",
      "2  0.40  0.42  0.57  0.35  0.5  0.0  0.53  0.25  negative\n",
      "3  0.46  0.44  0.52  0.11  0.5  0.0  0.50  0.22  negative\n",
      "4  0.47  0.39  0.50  0.11  0.5  0.0  0.49  0.40  negative\n",
      "Dataset X shape: (514, 8)\n",
      "Dataset Y shape: (514,)\n",
      "x_train shape: (462, 8)\n",
      "y_train shape: (462,)\n",
      "x_test shape: (52, 8)\n",
      "y_test shape: (52,)\n"
     ]
    }
   ],
   "source": [
    "header = ['Mcg', 'Gvh', 'Alm', 'Mit', 'Erl', 'Pox', 'Vac', 'Nuc', 'class']\n",
    "df = pd.read_csv('data/yeast-2_vs_4.dat', names=header, skiprows=13)\n",
    "print(df.head())\n",
    "df['class'] = df['class'].apply(lambda x:0 if x=='negative' else 1)\n",
    "\n",
    "df_np = df.to_numpy()\n",
    "x = df_np[:,:-1]\n",
    "y = df_np[:,-1]\n",
    "\n",
    "x = (x - x.mean(axis=0)) / x.var(axis=0)\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "ensemble_sizes = [10, 50, 100]\n",
    "\n",
    "print('Dataset X shape:', x.shape)\n",
    "print('Dataset Y shape:', y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=seed)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostM2:\n",
    "    def __init__(self, x, y, n_classifier, base=None, weights=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize AdaBoost M2 (Weight init is same as M1)\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        :param y: input label in shape of (samples, )\n",
    "        :param base: base classifier (default Decision Tree)\n",
    "        :param n_classifier: number of base classifier in ensemble\n",
    "        :param weights: init model with pretrained weights\n",
    "        \n",
    "        :return: A AdaBoost model\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.base = base\n",
    "        if self.base is None:\n",
    "            self.base = DecisionTreeClassifier\n",
    "        self.n_classifier = n_classifier\n",
    "        self.classifiers = []\n",
    "        self.weights = weights\n",
    "        self.alpha = []\n",
    "        self.bad_classifier_idx = []\n",
    "        \n",
    "        # init ensemble\n",
    "        for n in range(self.n_classifier):\n",
    "            self.classifiers.append(self.base(**kwargs))\n",
    "        \n",
    "        if self.weights is None:\n",
    "            # init weights using uniform distrobution\n",
    "            self.weights = np.ones(len(self.x)) / len(self.x)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (samples, )\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction = np.zeros((len(x),))\n",
    "        for idx in range(len(x)):\n",
    "            prediction[idx] = self.__predict_single_instance(x[idx].reshape(1, -1))\n",
    "        return prediction\n",
    "            \n",
    "    def __predict_single_instance(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (1, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (1, )\n",
    "        \"\"\"\n",
    "        p = np.zeros((1, 2))\n",
    "        for n in range(self.n_classifier):\n",
    "            if n not in self.bad_classifier_idx:\n",
    "                if self.classifiers[n].predict(x) == 1:\n",
    "                    p[0,1] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "                else:\n",
    "                    p[0,0] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "        p[:,1] += 1e-10 \n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the ensemble using base weak classifiers\n",
    "        \"\"\"\n",
    "        for t in range(self.n_classifier):            \n",
    "            \n",
    "            # training weak classifier\n",
    "            self.classifiers[t].fit(self.x, self.y, sample_weight=self.weights)\n",
    "                        \n",
    "            # calculating loss = sum of missclassified weights\n",
    "            miss_w = self.weights[(self.classifiers[t].predict(self.x) != self.y).nonzero()[0]]\n",
    "            loss = np.sum(miss_w) / 2 \n",
    "            \n",
    "            # calculating beta\n",
    "            a = loss / (1 - loss)\n",
    "            self.alpha.append(a)\n",
    "            \n",
    "            # drop classifiers with acc < 0.5\n",
    "            if self.classifiers[t].score(self.x, self.y) <= 0.5:\n",
    "                self.bad_classifier_idx.append(t)\n",
    "                continue\n",
    "#             print(a, self.n_classifier, self.classifiers[t].score(self.x, self.y))\n",
    "            # update weights\n",
    "            correct_pred_idx = (self.classifiers[t].predict(self.x) == self.y).nonzero()[0]\n",
    "            self.weights[correct_pred_idx] = self.weights[correct_pred_idx] * a\n",
    "            \n",
    "            # normalize weights\n",
    "            z = np.sum(self.weights)\n",
    "            self.weights = np.array([w / z for w in self.weights])\n",
    "             \n",
    "    \n",
    "    def score(self, x, y):\n",
    "        p = self.predict(x)\n",
    "        return np.sum((p == y)*1) / len(y)   \n",
    "\n",
    "# Test\n",
    "# model = AdaBoostM2(x=x_train, y=y_train, n_classifier=100, base=DecisionTreeClassifier, max_depth=1)\n",
    "# model.fit()\n",
    "# model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble with size of #10:\n",
      " [0.95145631067961167, 0.91262135922330101, 0.970873786407767, 0.96116504854368934, 0.90196078431372551] ---> AVG=0.9396154578336189\n",
      "Accuracy of ensemble with size of #50:\n",
      " [0.95145631067961167, 0.91262135922330101, 0.970873786407767, 0.96116504854368934, 0.90196078431372551] ---> AVG=0.9396154578336189\n",
      "Accuracy of ensemble with size of #100:\n",
      " [0.95145631067961167, 0.91262135922330101, 0.970873786407767, 0.96116504854368934, 0.90196078431372551] ---> AVG=0.9396154578336189\n"
     ]
    }
   ],
   "source": [
    "adaboost_accuracies = []  # accuracies of different ensembles given 5 folds\n",
    "for es in ensemble_sizes:\n",
    "    kf_acc = []  # accuracies of 5 fold\n",
    "    for train_index, test_index in kfold.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = AdaBoostM2(x=x_train, y=y_train, n_classifier=es, base=DecisionTreeClassifier, max_depth=1)\n",
    "        model.fit()\n",
    "        kf_acc.append(model.score(x_test, y_test))\n",
    "    adaboost_accuracies.append(kf_acc)\n",
    "for idx,f in enumerate(adaboost_accuracies):\n",
    "    print('Accuracy of ensemble with size of #{}:\\n {} ---> AVG={}'.format(\n",
    "        ensemble_sizes[idx], f, np.mean(adaboost_accuracies[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RUSBoost:\n",
    "    def __init__(self, x, y, n_classifier, base=None, weights=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize RUSBoost\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        :param y: input label in shape of (samples, )\n",
    "        :param base: base classifier (default Decision Tree)\n",
    "        :param n_classifier: number of base classifier in ensemble\n",
    "        :param weights: init model with pretrained weights\n",
    "        \n",
    "        :return: A RUSBoost model\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.base = base\n",
    "        if self.base is None:\n",
    "            self.base = DecisionTreeClassifier\n",
    "        self.n_classifier = n_classifier\n",
    "        self.classifiers = []\n",
    "        self.weights = weights\n",
    "        self.alpha = []\n",
    "        self.bad_classifier_idx = []\n",
    "        \n",
    "        # init ensemble\n",
    "        for n in range(self.n_classifier):\n",
    "            self.classifiers.append(self.base(**kwargs))\n",
    "        \n",
    "        if self.weights is None:\n",
    "            # init weights using uniform distrobution\n",
    "            self.weights = np.ones((len(self.x))) / len(self.x)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (samples, )\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction = np.zeros((len(x),))\n",
    "        for idx in range(len(x)):\n",
    "            prediction[idx] = self.__predict_single_instance(x[idx].reshape(1, -1))\n",
    "        return prediction\n",
    "            \n",
    "    def __predict_single_instance(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (1, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (1, )\n",
    "        \"\"\"\n",
    "        p = np.zeros((1, 2))\n",
    "        for n in range(self.n_classifier):\n",
    "            if n not in self.bad_classifier_idx:\n",
    "                if self.classifiers[n].predict(x) == 1:\n",
    "                    p[0,1] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "                else:\n",
    "                    p[0,0] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "        p[:,1] += 1e-10\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the ensemble using RUS data boosting and base weak classifiers\n",
    "        \"\"\"\n",
    "        for t in range(self.n_classifier):            \n",
    "            # random under sampling\n",
    "            rus_idx = self.__undersample()\n",
    "\n",
    "            # training weak classifier\n",
    "            self.classifiers[t].fit(self.x[rus_idx], self.y[rus_idx], self.weights[rus_idx])\n",
    "            \n",
    "            # calculating loss = sum of missclassified weights            \n",
    "            miss_w = self.weights[(self.classifiers[t].predict(self.x) != self.y).nonzero()[0]]\n",
    "            loss = np.sum(miss_w) / 2 \n",
    "            \n",
    "            # calculating beta\n",
    "            a = loss / (1 - loss)\n",
    "            self.alpha.append(a)\n",
    "            \n",
    "            # drop bad classifiers\n",
    "            if self.classifiers[t].score(self.x, self.y) <= 0.5:\n",
    "                self.bad_classifier_idx.append(t)\n",
    "                continue\n",
    "            \n",
    "            # update weights\n",
    "            correct_pred_idx = (self.classifiers[t].predict(self.x) == self.y).nonzero()[0]\n",
    "            self.weights[correct_pred_idx] = self.weights[correct_pred_idx] * a\n",
    "            \n",
    "            # normalize weights\n",
    "            z = np.sum(self.weights)\n",
    "            self.weights = np.array([w / z for w in self.weights])\n",
    "             \n",
    "    \n",
    "    def score(self, x, y):\n",
    "        p = self.predict(x)\n",
    "        return (p == y).nonzero()[0].__len__() / len(y)\n",
    "           \n",
    "    def __undersample(self):\n",
    "        \"\"\"\n",
    "        Generates a random unique subset of majority data as same size as minority and return the indices\n",
    "        \n",
    "        :return: A sorted list of indices with shape of (2*minority_data, )\n",
    "        \"\"\"\n",
    "        pos_size = len((self.y==1).nonzero()[0])\n",
    "        neg_size = len((self.y==0).nonzero()[0])\n",
    "        pos_data = self.x[self.y==1]\n",
    "        neg_data = self.x[self.y==0]\n",
    "        \n",
    "        if pos_size > neg_size:\n",
    "            self.major_data = pos_data\n",
    "            self.minor_data = neg_data\n",
    "            self.minor = 0\n",
    "        else:\n",
    "            self.minor_data = pos_data\n",
    "            self.major_data = neg_data\n",
    "            self.minor = 1\n",
    "        # getting index of sampled intances for enabling correct weight update\n",
    "        minor_idx = (self.y == self.minor).nonzero()[0]\n",
    "        major_idx = (self.y == int(not self.minor)).nonzero()[0]\n",
    "        major_idx = np.array(random.sample(list(major_idx), len(self.minor_data)))\n",
    "        return sorted(np.concatenate((minor_idx, major_idx)))\n",
    "    \n",
    "# test\n",
    "# model = RUSBoost(x=x_train, y=y_train, n_classifier=30, base=DecisionTreeClassifier, max_depth=1)\n",
    "# model.fit()\n",
    "# model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble with size of #10:\n",
      " [0.9223300970873787, 0.9320388349514563, 0.9320388349514563, 0.970873786407767, 0.9313725490196079] ---> AVG=0.9377308204835332\n",
      "Accuracy of ensemble with size of #50:\n",
      " [0.941747572815534, 0.9320388349514563, 0.9902912621359223, 0.970873786407767, 0.9215686274509803] ---> AVG=0.951304016752332\n",
      "Accuracy of ensemble with size of #100:\n",
      " [0.9320388349514563, 0.9223300970873787, 0.970873786407767, 0.9805825242718447, 0.9117647058823529] ---> AVG=0.94351798972016\n"
     ]
    }
   ],
   "source": [
    "rusboost_accuracies = []  # accuracies of different ensembles given 5 folds\n",
    "for es in ensemble_sizes:\n",
    "    kf_acc = []  # accuracies of 5 fold\n",
    "    for train_index, test_index in kfold.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = RUSBoost(x=x_train, y=y_train, n_classifier=es, base=DecisionTreeClassifier, max_depth=1)\n",
    "        model.fit()\n",
    "        kf_acc.append(model.score(x_test, y_test))\n",
    "    rusboost_accuracies.append(kf_acc)\n",
    "for idx,f in enumerate(rusboost_accuracies):\n",
    "    print('Accuracy of ensemble with size of #{}:\\n {} ---> AVG={}'.format(\n",
    "        ensemble_sizes[idx], f, np.mean(rusboost_accuracies[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMOTEBoost:\n",
    "    def __init__(self, x, y, n_classifier, k=5, smote_ratio=100, base=None, weights=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize AdaBoost M2 (Weight init is same as M1)\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        :param y: input label in shape of (samples, )\n",
    "        :param base: base classifier (default Decision Tree)\n",
    "        :param n_classifier: number of base classifier in ensemble\n",
    "        :param weights: init model with pretrained weights\n",
    "        :param smote_ratio: the ratio of smoteing data\n",
    "        :param k: number of nearest neighbors in SMOTE\n",
    "        \n",
    "        :return: A SMOTEBoost model\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.base = base\n",
    "        if self.base is None:\n",
    "            self.base = DecisionTreeClassifier\n",
    "        self.n_classifier = n_classifier\n",
    "        self.smote_ratio = smote_ratio  # alias N\n",
    "        self.k = k\n",
    "        self.classifiers = []\n",
    "        self.weights = weights\n",
    "        self.alpha = []\n",
    "        self.newindex = 0  # to count SMOTEed samples\n",
    "        self.synthetic = []  # SMOTEed samples\n",
    "        self.bad_classifier_idx = []\n",
    "        \n",
    "        # init ensemble\n",
    "        for n in range(self.n_classifier):\n",
    "            self.classifiers.append(self.base(**kwargs))\n",
    "            \n",
    "    def __SMOTE(self):\n",
    "        \"\"\"\n",
    "        Applies SMOTE on data\n",
    "        \n",
    "        :return: SMOTEed data in shape of (N*T/100)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.synthetic = []  # reinit synthetic for new SMOTEing\n",
    "        \n",
    "        pos_size = len((self.y==1).nonzero()[0])\n",
    "        neg_size = len((self.y==0).nonzero()[0])\n",
    "        pos_data = self.x[self.y==1]\n",
    "        neg_data = self.x[self.y==0]\n",
    "        \n",
    "        if pos_size > neg_size:\n",
    "            self.major_data = pos_data\n",
    "            self.minor_data = neg_data\n",
    "            self.minor = 0\n",
    "        else:\n",
    "            self.minor_data = pos_data\n",
    "            self.major_data = neg_data\n",
    "            self.minor = 1\n",
    "        \n",
    "        N = self.smote_ratio\n",
    "        T = len(self.minor_data)\n",
    "        T = int(N * T / 100)\n",
    "             \n",
    "        while T != 0:\n",
    "            i = np.random.randint(1, len(self.minor_data)) - 1\n",
    "            self.__populate(i, self.__KNN(i))\n",
    "            T = T - 1\n",
    "        \n",
    "        return np.array(self.synthetic)\n",
    "        \n",
    "    def __KNN(self, idx):\n",
    "        \"\"\"\n",
    "        Applies SMOTE on data\n",
    "        \n",
    "        :param idx: index of an instance of input data (x)\n",
    "        :return: k indices of nearest neighbor to the given instance\n",
    "        \"\"\"\n",
    "        \n",
    "        distances = []\n",
    "        for i in range(len(self.minor_data)):\n",
    "            if i != idx:\n",
    "                distances.append(((np.sqrt(np.sum(self.minor_data[idx] - self.minor_data[i])**2)), i))\n",
    "        # get k nearest\n",
    "        distances = sorted(distances, key=lambda x:x[0])\n",
    "        return [en[1] for en in distances[:self.k]]\n",
    "                \n",
    "    def __populate(self, i, knn):\n",
    "        \"\"\"\n",
    "        Create synthetic instances given particular instance and its K nearest neighbors\n",
    "        \n",
    "        :param i: index of current sample to generated SMOTE from\n",
    "        :param knn: index of k nearest neighbors of current sample i\n",
    "        :return: None - Updates self.synthetic \n",
    "        \"\"\"\n",
    "        \n",
    "        nn = np.random.randint(0, len(knn))\n",
    "        diff = self.minor_data[knn[nn]] - self.minor_data[i]\n",
    "        gap = np.random.randn(self.minor_data.shape[1])\n",
    "        self.synthetic.insert(self.newindex, self.minor_data[i] + gap * diff)\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the ensemble using base weak classifiers\n",
    "        \"\"\"\n",
    "        syn_data = self.__SMOTE()  # just to determine sizes\n",
    "        if self.weights is None:\n",
    "            # init weights using uniform distrobution\n",
    "            self.weights = np.ones((len(syn_data)+len(self.x))) / (len(syn_data)+len(self.x))\n",
    "        \n",
    "        for t in range(self.n_classifier):            \n",
    "            # SMOTE data\n",
    "            syn_data = self.__SMOTE()\n",
    "            x_smote = np.concatenate((self.x, syn_data))\n",
    "            y_smote = np.concatenate((self.y, np.ones((len(syn_data)))*self.minor))\n",
    "            \n",
    "            # training weak classifier\n",
    "            self.classifiers[t].fit(x_smote, y_smote, self.weights)\n",
    "            \n",
    "            # calculating loss = sum of missclassified weights\n",
    "            miss_w = self.weights[(self.classifiers[t].predict(x_smote) != y_smote).nonzero()[0]]\n",
    "            loss = np.sum(miss_w) / 2 \n",
    "            \n",
    "            # calculating beta\n",
    "            a = loss / (1 - loss)\n",
    "            self.alpha.append(a)\n",
    "            \n",
    "            # drop bad classifiers\n",
    "            if self.classifiers[t].score(self.x, self.y) <= 0.5:\n",
    "                self.bad_classifier_idx.append(t)\n",
    "                continue\n",
    "            \n",
    "            # update weights\n",
    "            correct_pred_idx = (self.classifiers[t].predict(x_smote) == y_smote).nonzero()[0]\n",
    "            self.weights[correct_pred_idx] = self.weights[correct_pred_idx] * a\n",
    "            \n",
    "            # normalize weights\n",
    "            z = np.sum(self.weights)\n",
    "            self.weights = np.array([w / z for w in self.weights])\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (samples, )\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction = np.zeros((len(x),))\n",
    "        for idx in range(len(x)):\n",
    "            prediction[idx] = self.__predict_single_instance(x[idx].reshape(1, -1))\n",
    "        return prediction\n",
    "            \n",
    "    def __predict_single_instance(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (1, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (1, )\n",
    "        \"\"\"\n",
    "        p = np.zeros((1, 2))\n",
    "        for n in range(self.n_classifier):\n",
    "            if n not in self.bad_classifier_idx:\n",
    "                if self.classifiers[n].predict(x) == 1:\n",
    "                    p[0,1] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "                else:\n",
    "                    p[0,0] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "        p[:,1] += 1e-10\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        p = self.predict(x)\n",
    "        return (p == y).nonzero()[0].__len__() / len(y)\n",
    "        \n",
    "# test\n",
    "# model = SMOTEBoost(x=x_train, y=y_train, n_classifier=30, smote_ratio=200, base=DecisionTreeClassifier, max_depth=1)\n",
    "# model.fit()\n",
    "# model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble with size of #10:\n",
      " [0.9611650485436893, 0.9320388349514563, 0.970873786407767, 0.9611650485436893, 0.9215686274509803] ---> AVG=0.9493622691795165\n",
      "Accuracy of ensemble with size of #50:\n",
      " [0.9320388349514563, 0.9320388349514563, 0.970873786407767, 0.9805825242718447, 0.9509803921568627] ---> AVG=0.9533028745478773\n",
      "Accuracy of ensemble with size of #100:\n",
      " [0.9611650485436893, 0.941747572815534, 0.9514563106796117, 0.970873786407767, 0.9313725490196079] ---> AVG=0.951323053493242\n"
     ]
    }
   ],
   "source": [
    "smoteboost_accuracies = []  # accuracies of different ensembles given 5 folds\n",
    "for es in ensemble_sizes:\n",
    "    kf_acc = []  # accuracies of 5 fold\n",
    "    for train_index, test_index in kfold.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = SMOTEBoost(x=x_train, y=y_train, n_classifier=es, \n",
    "                           smote_ratio=200, base=DecisionTreeClassifier, max_depth=1)\n",
    "        model.fit()\n",
    "        kf_acc.append(model.score(x_test, y_test))\n",
    "    smoteboost_accuracies.append(kf_acc)\n",
    "for idx,f in enumerate(smoteboost_accuracies):\n",
    "    print('Accuracy of ensemble with size of #{}:\\n {} ---> AVG={}'.format(\n",
    "        ensemble_sizes[idx], f, np.mean(smoteboost_accuracies[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBBoost:\n",
    "    def __init__(self, x, y, n_classifier, k=5, base=None, weights=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize AdaBoost M2 (Weight init is same as M1)\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        :param y: input label in shape of (samples, )\n",
    "        :param base: base classifier (default Decision Tree)\n",
    "        :param n_classifier: number of base classifier in ensemble\n",
    "        :param weights: init model with pretrained weights\n",
    "        :param k: number of nearest neighbors in SMOTE\n",
    "        \n",
    "        :return: A RBBoost model\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.base = base\n",
    "        if self.base is None:\n",
    "            self.base = DecisionTreeClassifier\n",
    "        self.n_classifier = n_classifier\n",
    "        self.k = k\n",
    "        self.classifiers = []\n",
    "        self.weights = weights\n",
    "        self.alpha = []\n",
    "        self.newindex = 0  # to count SMOTEed samples\n",
    "        self.synthetic = []  # SMOTEed samples\n",
    "        self.bad_classifier_idx = []\n",
    "        \n",
    "        # init ensemble\n",
    "        for n in range(self.n_classifier):\n",
    "            self.classifiers.append(self.base(**kwargs))\n",
    "            \n",
    "        if self.weights is None:\n",
    "            # init weights using uniform distrobution\n",
    "            self.weights = np.ones(len(self.x)) / len(self.x)\n",
    "    \n",
    "    def __random_balance(self):\n",
    "        \"\"\"\n",
    "        Applies random balance algorithm to generate new data\n",
    "        \n",
    "        :return: a tuple of 2 numpy array of x and y (new_x, new_y, smoteing size)\n",
    "        \"\"\"\n",
    "        new_x = []\n",
    "        new_y = []\n",
    "        \n",
    "        total_size = len(self.x)\n",
    "        pos_size = len((self.y==1).nonzero()[0])\n",
    "        neg_size = len((self.y==0).nonzero()[0])\n",
    "        pos_data = self.x[self.y==1]\n",
    "        neg_data = self.x[self.y==0]\n",
    "        \n",
    "        if pos_size > neg_size:\n",
    "            self.major_data = pos_data\n",
    "            self.minor_data = neg_data\n",
    "            self.minor = 0\n",
    "        else:\n",
    "            self.minor_data = pos_data\n",
    "            self.major_data = neg_data\n",
    "            self.minor = 1\n",
    "            \n",
    "        majority_size = len(self.major_data)\n",
    "        minority_size = len(self.minor_data)\n",
    "        new_majority_size = np.random.randint(2, total_size - 2)\n",
    "        new_minority_size = total_size - new_majority_size\n",
    "        \n",
    "        if new_majority_size < majority_size:\n",
    "            new_x.extend(self.minor_data)\n",
    "            new_y.extend([1] * minority_size)\n",
    "            random_majority = random.sample(list(self.major_data), new_majority_size)\n",
    "            new_x.extend(random_majority)\n",
    "            new_y.extend([0] * new_majority_size)\n",
    "            smote = self.__SMOTE((new_minority_size-minority_size) * 100 / minority_size, self.minor_data)\n",
    "            new_x.extend(smote)\n",
    "            new_y.extend([1] * len(smote))\n",
    "        else:\n",
    "            new_x.extend(self.major_data)\n",
    "            new_y.extend([0] * majority_size)\n",
    "            random_minority = random.sample(list(self.minor_data), new_minority_size)\n",
    "            new_x.extend(random_minority)\n",
    "            new_y.extend([1] * new_minority_size)\n",
    "            smote = self.__SMOTE((new_majority_size-majority_size) * 100 / majority_size, self.major_data)\n",
    "            new_x.extend(smote)\n",
    "            new_y.extend([0] * len(smote))\n",
    "        return (np.array(new_x), np.array(new_y), len(smote))\n",
    "            \n",
    "    \n",
    "    def __SMOTE(self, smote_ratio, data):\n",
    "        \"\"\"\n",
    "        Applies SMOTE on data\n",
    "        \n",
    "        :param data: data to SMOTE\n",
    "        :param smote_ratio: The amount of SMOTEing data\n",
    "        :return: SMOTEed data in shape of (N*T/100)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.synthetic = []  # reinit synthetic for new SMOTEing\n",
    "        N = smote_ratio\n",
    "        T = N * len(data) / 100\n",
    "        if T % 2 != 0:  # just solving size mismatch\n",
    "            T = round(N * len(data) / 100)\n",
    "             \n",
    "        while T != 0:\n",
    "            i = np.random.randint(1, len(data)) - 1\n",
    "            self.__populate(i, self.__KNN(i, data), data)\n",
    "            T = T - 1\n",
    "        \n",
    "        return np.array(self.synthetic)\n",
    "        \n",
    "    def __KNN(self, idx, data):\n",
    "        \"\"\"\n",
    "        Applies SMOTE on data\n",
    "        \n",
    "        :param data: data to extract nearest neighbors\n",
    "        :param idx: index of an instance of input data (x)\n",
    "        :return: k indices of nearest neighbor to the given instance\n",
    "        \"\"\"\n",
    "        \n",
    "        distances = []\n",
    "        for i in range(len(data)):\n",
    "            if i != idx:\n",
    "                distances.append(((np.sqrt(np.sum(data[idx] - data[i])**2)), i))\n",
    "        # get k nearest\n",
    "        distances = sorted(distances, key=lambda x:x[0])\n",
    "        return [en[1] for en in distances[:self.k]]\n",
    "                \n",
    "    def __populate(self, i, knn, data):\n",
    "        \"\"\"\n",
    "        Create synthetic instances given particular instance and its K nearest neighbors\n",
    "        \n",
    "        :param data: data to generate artificial samples\n",
    "        :param i: index of current sample to generated SMOTE from\n",
    "        :param knn: index of k nearest neighbors of current sample i\n",
    "        :return: None - Updates self.synthetic \n",
    "        \"\"\"\n",
    "        \n",
    "        nn = np.random.randint(0, len(knn))\n",
    "        diff = data[knn[nn]] - data[i]\n",
    "        gap = np.random.randn(data.shape[1])\n",
    "        self.synthetic.insert(self.newindex, data[i] + gap * diff)\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the ensemble using base weak classifiers\n",
    "        \"\"\"\n",
    "        for t in range(self.n_classifier):            \n",
    "            # SMOTE data\n",
    "            x_rb, y_rb, syn_size = self.__random_balance()\n",
    "            \n",
    "            # init artificial sample weights\n",
    "            w =  np.ones(len(self.x)) / len(self.x)\n",
    "            w[:-syn_size] = self.weights[:-syn_size]\n",
    "            self.weights = w\n",
    "            \n",
    "            # training weak classifier\n",
    "            self.classifiers[t].fit(x_rb, y_rb, self.weights)\n",
    "            \n",
    "            # calculating loss = sum of missclassified weights\n",
    "            miss_w = self.weights[(self.classifiers[t].predict(x_rb) != y_rb).nonzero()[0]]\n",
    "            loss = np.sum(miss_w) / 2 \n",
    "            \n",
    "            # calculating beta\n",
    "            a = loss / (1 - loss)\n",
    "            self.alpha.append(a)\n",
    "            \n",
    "            # drop bad classifiers\n",
    "            if self.classifiers[t].score(self.x, self.y) <= 0.5:\n",
    "                self.bad_classifier_idx.append(t)\n",
    "                continue\n",
    "            \n",
    "            # update weights\n",
    "            correct_pred_idx = (self.classifiers[t].predict(x_rb) == y_rb).nonzero()[0]\n",
    "            self.weights[correct_pred_idx] = self.weights[correct_pred_idx] * a\n",
    "            \n",
    "            # normalize weights\n",
    "            z = np.sum(self.weights)\n",
    "            self.weights = np.array([w / z for w in self.weights])\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (samples, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (samples, )\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction = np.zeros((len(x),))\n",
    "        for idx in range(len(x)):\n",
    "            prediction[idx] = self.__predict_single_instance(x[idx].reshape(1, -1))\n",
    "        return prediction\n",
    "            \n",
    "    def __predict_single_instance(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of given instance\n",
    "        \n",
    "        :param x: input feauture in shape of (1, features)\n",
    "        \n",
    "        :return: a prediction of classes in label encoded form with shape of (1, )\n",
    "        \"\"\"\n",
    "        p = np.zeros((1, 2))\n",
    "        for n in range(self.n_classifier):\n",
    "            if n not in self.bad_classifier_idx:\n",
    "                if self.classifiers[n].predict(x) == 1:\n",
    "                    p[0,1] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "                else:\n",
    "                    p[0,0] += np.log(1 / (self.alpha[n]+1e-10))\n",
    "        p[:,1] += 1e-10\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        \"\"\"\n",
    "        Reports the score of model given x and y test\n",
    "        \"\"\"\n",
    "        p = self.predict(x)\n",
    "        return (p == y).nonzero()[0].__len__() / len(y)\n",
    "\n",
    "# test\n",
    "# model = RBBoost(x=x_train, y=y_train, n_classifier=30, base=DecisionTreeClassifier, max_depth=1)\n",
    "# model.fit()\n",
    "# model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble with size of #10:\n",
      " [0.9320388349514563, 0.941747572815534, 0.9805825242718447, 0.970873786407767, 0.9215686274509803] ---> AVG=0.9493622691795165\n",
      "Accuracy of ensemble with size of #50:\n",
      " [0.9611650485436893, 0.9320388349514563, 0.9805825242718447, 0.9514563106796117, 0.9215686274509803] ---> AVG=0.9493622691795165\n",
      "Accuracy of ensemble with size of #100:\n",
      " [0.9611650485436893, 0.9611650485436893, 0.9805825242718447, 0.9611650485436893, 0.9215686274509803] ---> AVG=0.9571292594707786\n"
     ]
    }
   ],
   "source": [
    "rbboost_accuracies = []  # accuracies of different ensembles given 5 folds\n",
    "for es in ensemble_sizes:\n",
    "    kf_acc = []  # accuracies of 5 fold\n",
    "    for train_index, test_index in kfold.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = RBBoost(x=x_train, y=y_train, n_classifier=es, base=DecisionTreeClassifier, max_depth=1)\n",
    "        model.fit()\n",
    "        kf_acc.append(model.score(x_test, y_test))\n",
    "    rbboost_accuracies.append(kf_acc)\n",
    "for idx,f in enumerate(rbboost_accuracies):\n",
    "    print('Accuracy of ensemble with size of #{}:\\n {} ---> AVG={}'.format(\n",
    "        ensemble_sizes[idx], f, np.mean(rbboost_accuracies[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy \n",
      " [0.970873786407767, 0.92233009708737868, 0.94174757281553401, 0.93203883495145634, 0.90196078431372551] ---> AVG=0.9337902151151724\n"
     ]
    }
   ],
   "source": [
    "svc_accuracies = []  # accuracies of different ensembles given 5 folds\n",
    "kf_acc = []  # accuracies of 5 fold\n",
    "for train_index, test_index in kfold.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = SVC(gamma='scale')\n",
    "    model.fit(x_train, y_train)\n",
    "    kf_acc.append(model.score(x_test, y_test))\n",
    "svc_accuracies.append(kf_acc)\n",
    "for idx,f in enumerate(svc_accuracies):\n",
    "    print('Accuracy \\n {} ---> AVG={}'.format(f, np.mean(svc_accuracies[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble with size of #10:\n",
      " [0.98058252427184467, 0.88349514563106801, 0.95145631067961167, 0.90291262135922334, 0.89215686274509809] ---> AVG=0.9221206929373691\n",
      "Accuracy of ensemble with size of #50:\n",
      " [0.96116504854368934, 0.88349514563106801, 0.95145631067961167, 0.90291262135922334, 0.90196078431372551] ---> AVG=0.9201979821054636\n",
      "Accuracy of ensemble with size of #100:\n",
      " [0.91262135922330101, 0.89320388349514568, 0.95145631067961167, 0.90291262135922334, 0.90196078431372551] ---> AVG=0.9124309918142014\n"
     ]
    }
   ],
   "source": [
    "randomforest_accuracies = []  # accuracies of different ensembles given 5 folds\n",
    "for es in ensemble_sizes:\n",
    "    kf_acc = []  # accuracies of 5 fold\n",
    "    for train_index, test_index in kfold.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = RandomForestClassifier(n_estimators=es, max_depth=1)\n",
    "        model.fit(x_train, y_train)\n",
    "        kf_acc.append(model.score(x_test, y_test))\n",
    "    randomforest_accuracies.append(kf_acc)\n",
    "for idx,f in enumerate(randomforest_accuracies):\n",
    "    print('Accuracy of ensemble with size of #{}:\\n {} ---> AVG={}'.format(\n",
    "        ensemble_sizes[idx], f, np.mean(randomforest_accuracies[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_acc = np.concatenate((np.array(adaboost_accuracies).mean(axis=1).reshape(-1, 1), \n",
    "                          np.array(rusboost_accuracies).mean(axis=1).reshape(-1, 1),\n",
    "                          np.array(smoteboost_accuracies).mean(axis=1).reshape(-1, 1),\n",
    "                          np.array(rbboost_accuracies).mean(axis=1).reshape(-1, 1),\n",
    "                          np.array([np.mean(svc_accuracies), np.mean(svc_accuracies), np.mean(svc_accuracies)]).reshape(-1, 1),\n",
    "                          np.array(randomforest_accuracies).mean(axis=1).reshape(-1, 1)), axis=1)\n",
    "\n",
    "columns = ('AdaBoost', 'RUSBoost', 'SMOTEBoost', 'RBBoost', 'SVC', 'RandomForest')\n",
    "rows = ['100', '50', '10']\n",
    "\n",
    "n_rows = len(all_acc)\n",
    "index = np.arange(len(columns)) + 0.3\n",
    "bar_width = 0.4\n",
    "y_offset = np.zeros(len(columns))\n",
    "colors = plt.cm.jet(np.linspace(0, 0.5, len(rows)))\n",
    "values = np.arange(0, 10, 100)\n",
    "value_increment = 1\n",
    "\n",
    "cell_text = []\n",
    "for row in range(n_rows):\n",
    "    plt.bar(index, all_acc[row], bar_width, bottom=y_offset, color=colors[row])\n",
    "    cell_text.append(['%1.5f' % (x) for x in all_acc[row]])\n",
    "# Reverse colors and text labels to display the last value at the top.\n",
    "colors = colors[::-1]\n",
    "cell_text.reverse()\n",
    "\n",
    "# Add a table at the bottom of the axes\n",
    "the_table = plt.table(cellText=cell_text,\n",
    "                      rowLabels=rows,\n",
    "                      rowColours=colors,\n",
    "                      colLabels=columns,\n",
    "                      loc='bottom')\n",
    "\n",
    "# Adjust layout to make room for the table:\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.yticks(values * value_increment, ['%d' % val for val in values])\n",
    "plt.xticks([])\n",
    "plt.title('Accuracy of ensembles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble10 = all_acc[0]\n",
    "ensemble50 = all_acc[1]\n",
    "ensemble100 = all_acc[2]\n",
    "\n",
    "values = np.arange(len(columns))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(values - width, ensemble10, width, label='L=10')\n",
    "rects2 = ax.bar(values, ensemble50, width, label='L=50')\n",
    "rects3 = ax.bar(values + width, ensemble100, width, label='L=100')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(values)\n",
    "ax.set_xticklabels(columns)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('%0.3f' % height,\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(14,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
